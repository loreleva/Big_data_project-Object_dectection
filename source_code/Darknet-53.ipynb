{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e074c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6525c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9e0df",
   "metadata": {},
   "source": [
    "# Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76f3e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple: (filters, size, stride), single convolutional layer\n",
    "\n",
    "# [\"residual\", repetitions]: residual layers, let prev_channel be the number of channels of the previous layer,\n",
    "# the sequence of conv with filters of size: prev_channels//2 ---> prev_channels ---> residual connection\n",
    "# is repeated for \"repetitions\" times\n",
    "\n",
    "# [\"residualYolo\", repetitions]: same as \"residual\" but some feature maps are saved to be used with the YOLO network\n",
    "\n",
    "# [\"avgpool\"]: avearge pooling with output of size 1x1 for each channel\n",
    "\n",
    "# [\"prediction\"]: last convolutional layer which produces a number of channels equal to the number of classes\n",
    "\n",
    "\n",
    "darknet_architecture = [\n",
    "    (32, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"residual\", 1],\n",
    "    (128, 3, 2),\n",
    "    [\"residual\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"residualYolo\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"residualYolo\", 8],\n",
    "    (1024, 3, 2),\n",
    "    [\"residual\", 4],\n",
    "    [\"avgpool\"],\n",
    "    [\"prediction\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74073eab",
   "metadata": {},
   "source": [
    "# Blocks Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83df9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bn_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        padding=1 if kernel_size == 3 else 0\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              bias=not bn_act,\n",
    "                              padding=padding, \n",
    "                              **kwargs)\n",
    "        # if batchnorm, then leaky relu as activation function\n",
    "        self.use_bn_act = bn_act\n",
    "        if self.use_bn_act:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "            self.leaky = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn_act:\n",
    "            return self.leaky(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b99d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    ConvLayer(channels, channels // 2, kernel_size=1),\n",
    "                    ConvLayer(channels // 2, channels, kernel_size=3),\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "        self.num_repeats = num_repeats\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) + self.use_residual * x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13153b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block of convolutional layers with feature map to be saved for detections\n",
    "class ConvBlockYolo(nn.Module):\n",
    "    def __init__(self, channels, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.feat_map = None\n",
    "        num_layer = 1\n",
    "        for i in range(num_repeats):\n",
    "            if num_layer == 5:\n",
    "                self.layers += [\n",
    "                    ConvLayer(channels, channels // 2, kernel_size=1),\n",
    "                    ConvLayer(channels // 2, channels, kernel_size=3)\n",
    "                ]\n",
    "            else:\n",
    "                self.layers += [\n",
    "                    nn.Sequential(\n",
    "                        ConvLayer(channels, channels // 2, kernel_size=1),\n",
    "                        ConvLayer(channels // 2, channels, kernel_size=3),\n",
    "                    )\n",
    "                ]\n",
    "            num_layer += 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.feat_map = None\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ConvLayer):\n",
    "                if self.feat_map == None:\n",
    "                    self.feat_map = layer(x)\n",
    "                else:\n",
    "                    x = layer(self.feat_map) + x\n",
    "            else:\n",
    "                x = layer(x) + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cc016",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63ca12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class darknet53(nn.Module):\n",
    "    def __init__(self, architecture, num_classes, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.layers = self._create_layers(architecture)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.reshape(x.shape[0], x.shape[1])\n",
    "        return x\n",
    "        \n",
    "    def _create_layers(self, architecture):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "        for module in architecture:\n",
    "            # conv layer\n",
    "            if isinstance(module, tuple):\n",
    "                if module[-1] == \"linear\":\n",
    "                    bn_act = False\n",
    "                else:\n",
    "                    bn_act = True\n",
    "                layers.append(ConvLayer(in_channels, \n",
    "                                        module[0], \n",
    "                                        kernel_size=module[1],\n",
    "                                        bn_act=bn_act,\n",
    "                                        stride=module[2])\n",
    "                             )\n",
    "                in_channels = module[0]\n",
    "                continue\n",
    "            \n",
    "            if isinstance(module, list):\n",
    "                # residual block\n",
    "                if module[0] == \"residual\":\n",
    "                    layers.append(ConvBlock(in_channels,\n",
    "                                            num_repeats=module[1])\n",
    "                                 )\n",
    "                    continue\n",
    "                    \n",
    "                # residual block with feature map to be saved for detection\n",
    "                elif module[0] == \"residualYolo\":\n",
    "                    layers.append(ConvBlockYolo(in_channels,\n",
    "                                            num_repeats=module[1])\n",
    "                                 )\n",
    "                \n",
    "                # average pool\n",
    "                elif module[0] == \"avgpool\":\n",
    "                    layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "                    continue\n",
    "                \n",
    "                # last convolutional layer\n",
    "                elif module[0] == \"prediction\":\n",
    "                    layers.append(ConvLayer(in_channels,\n",
    "                                            self.num_classes,\n",
    "                                            kernel_size=1,\n",
    "                                            bn_act=False,\n",
    "                                            stride=1)\n",
    "                                 )\n",
    "                    continue\n",
    "                    \n",
    "        return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01b97b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1627a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgnet_trainset(Dataset):\n",
    "    def __init__(self, df, path=\"./ImageNet_darknet_dataset/data/images\"):\n",
    "        self.transform = transforms.PILToTensor()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.path, row[\"filename\"].split(\"_\")[0], row[\"filename\"]))\n",
    "        return (self.transform(img).float()/255, row[\"label\"])\n",
    "    \n",
    "class imgnet_testset(Dataset):\n",
    "    def __init__(self, df, path=\"./ImageNet_darknet_dataset/data/images\"):\n",
    "        self.transform = transforms.PILToTensor()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.path, row[\"filename\"].split(\"_\")[0], row[\"filename\"]))\n",
    "        return (self.transform(img).float()/255, row[\"label\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e35ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path=\"./ImageNet_darknet_dataset\"):\n",
    "    # in trainset, occurrences of classes goes from a max of 1200 to a minimum of 632, mean: 499\n",
    "    df_main = pd.read_csv(os.path.join(path, \"main.csv\"), sep=\";\", skipinitialspace=True)\n",
    "    testset_df = pd.DataFrame(columns=[\"filename\", \"label\"])\n",
    "    trainset_df = pd.DataFrame(columns=[\"filename\", \"label\"])\n",
    "    for idx in range(len(df_main)):\n",
    "        print(f\"CLASS {idx+1}/1000\")\n",
    "        row = df_main.iloc[idx]\n",
    "        path_class_csv = os.path.join(path, \"data\", \"info_classes\", f\"class_{row['label']}.csv\")\n",
    "        df_cls = pd.read_csv(path_class_csv, sep=\";\", skipinitialspace=True)\n",
    "        # for trainset sample 100 images for each class, trainset size is 100k\n",
    "        df_testset_sample = df_cls.sample(100)\n",
    "        df_cls = df_cls.drop(list(df_testset_sample.index.values))\n",
    "        df_cls = df_cls.sample(500)\n",
    "        # add splitted dataframes to trainset and testset dataframes\n",
    "        testset_df = pd.concat([testset_df, df_testset_sample], axis=0)\n",
    "        trainset_df = pd.concat([trainset_df, df_cls], axis=0)\n",
    "    return imgnet_trainset(trainset_df), imgnet_testset(testset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335c4aa",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389c05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "augmentation = A.Compose(\n",
    "    [\n",
    "        A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "        A.Blur(p=0.1),\n",
    "        A.CLAHE(p=0.1),\n",
    "        A.Posterize(p=0.1),\n",
    "        A.ToGray(p=0.1),\n",
    "        A.ChannelShuffle(p=0.05),\n",
    "\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64df73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform agumentation when loading batch\n",
    "def collate_fn_padd(batch):\n",
    "    X = None\n",
    "    Y = None\n",
    "    for img, y in batch:\n",
    "        img_numpy = (torch.permute(img, (1, 2, 0))*255).numpy().astype(np.uint8)\n",
    "        img_numpy = augmentation(image=img_numpy)[\"image\"]\n",
    "        tensor_augm = torch.permute(torch.from_numpy(img_numpy), (2, 0, 1)) / 255\n",
    "        if X == None:\n",
    "            X = torch.stack((img, tensor_augm))\n",
    "            Y = torch.cat((y, y))\n",
    "        else:\n",
    "            X = torch.cat((X, img.unsqueeze(0), tensor_augm.unsqueeze(0)))\n",
    "            Y = torch.cat((Y, y, y))\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "062310a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 1000\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c090d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset, testset = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f36a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "darknet = darknet53(darknet_architecture, classes).to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=darknet.parameters(), lr=lr)\n",
    "i=1\n",
    "\n",
    "best_parameters = None\n",
    "best_loss = math.inf\n",
    "while(True):\n",
    "    losses = []\n",
    "    n_batch = 0\n",
    "    train_loader = DataLoader(trainset, batch_size=8, shuffle=True)\n",
    "    total_batches = len(train_loader)\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = darknet(x)\n",
    "        loss = ce_loss(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if n_batch % 1000 == 0:\n",
    "            print(f\"BATCH: {n_batch+1}/{total_batches}\")\n",
    "            print(f\"loss: {loss.item()}\\n\")\n",
    "        n_batch+=1\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    mean_losses = sum(losses)/len(losses)\n",
    "    if mean_losses < best_loss:\n",
    "        if best_loss != math.inf:\n",
    "            os.remove(f\"../backup_models/darknet_weights_loss_{best_loss}\")\n",
    "        best_loss = mean_losses\n",
    "        best_parameters = darknet.state_dict()\n",
    "        torch.save(best_parameters, f\"../backup_models/darknet_weights_loss_{best_loss}\")\n",
    "    print(f\"EPOCH: {i} MEAN LOSSES EPOCH: {sum(losses)/len(losses)}\")\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(testset)\n",
    "print(f\"N :{N}\")\n",
    "top1 = 0\n",
    "top5 = 0\n",
    "i=1\n",
    "with torch.no_grad():\n",
    "    batch_size = 8\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size)\n",
    "    N_test_loader = len(test_loader)\n",
    "    for x, y in test_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = darknet(x)\n",
    "        \n",
    "        for idx_batch in range(x.shape[0]):\n",
    "            top1_pred = torch.argmax(pred[idx_batch])\n",
    "            if top1_pred == y[idx_batch]:\n",
    "                top1 += 1\n",
    "                top5 += 1\n",
    "                continue\n",
    "            \n",
    "            top5_pred = torch.topk(pred[idx_batch], 5).indices\n",
    "            if y[idx_batch] in top5_pred:\n",
    "                top5 += 1\n",
    "        if i%1000 == 0:\n",
    "            print(f\"{i}/{N_test_loader}\")\n",
    "        i+=1\n",
    "        \n",
    "print(f\"ACCURACY TOP1: {top1/N}\")\n",
    "print(f\"ACCURACY TOP5: {top5/N}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
